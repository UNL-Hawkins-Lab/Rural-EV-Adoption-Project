b11.18 <-
brm(data = d,
family = categorical(link = logit, refcat = NA),
bf(career ~ 1,
nlf(mu1 ~ a1 + b1 * family_income),
nlf(mu2 ~ a2 + b2 * family_income),
nlf(mu3 ~ b3 * family_income),
mvbind(a1 + a2 +  b1 + b2 + b3) ~ 1 + (1|id)),
prior = c(prior(normal(0, 1.5), class = b, nlpar = a1),
prior(normal(0, 1.5), class = b, nlpar = a2),
prior(normal(0, 1), class = b, nlpar = b1),
prior(normal(0, 1), class = b, nlpar = b2),
prior(normal(0, 1), class = b, nlpar = b3)),
iter = 2000, warmup = 1000, cores = 4, chains = 4,
seed = 11,
file = "b11.18")
summary(b11.18)
b11.19 <-
brm(data = d,
family = categorical(link = logit, refcat = NA),
bf(career ~ 1,
nlf(mu1 ~ a1 + b1 * family_income),
nlf(mu2 ~ a2 + b2 * family_income),
nlf(mu3 ~ b3 * family_income),
mvbind(a1,a2,b1,b2,b3) ~ 1 + (1|id)),
prior = c(prior(normal(0, 1.5), class = b, nlpar = a1),
prior(normal(0, 1.5), class = b, nlpar = a2),
prior(normal(0, 1), class = b, nlpar = b1),
prior(normal(0, 1), class = b, nlpar = b2),
prior(normal(0, 1), class = b, nlpar = b3)),
iter = 2000, warmup = 1000, cores = 4, chains = 4,
seed = 11,
file = "b11.19")
summary(b11.19)
stancode(             brm(data = d,
family = categorical(link = logit, refcat = NA),
bf(career ~ 1,
nlf(mu1 ~ a1 + b1 * family_income),
nlf(mu2 ~ a2 + b2 * family_income),
nlf(mu3 ~ b3 * family_income),
mvbind(a1,a2,b1,b2,b3) ~ 1 + (1|id)),
prior = c(prior(normal(0, 1.5), class = b, nlpar = a1),
prior(normal(0, 1.5), class = b, nlpar = a2),
prior(normal(0, 1), class = b, nlpar = b1),
prior(normal(0, 1), class = b, nlpar = b2),
prior(normal(0, 1), class = b, nlpar = b3)),
iter = 2000, warmup = 1000, cores = 4, chains = 4,
seed = 11,
file = "b11.19"))
reticulate::repl_python()
import geoplot as gplt
import geopandas as gpd
import geoplot.crs as gcrs
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import mapclassify as mc
import numpy as np
from geopy.geocoders import Nominatim
from shapely.geometry import Point
import os
from pandasql import sqldf
import matplotlib.pyplot as plt
import matplotlib as mpl
import datetime
import numpy as np
pysqldf = lambda q: sqldf(q, globals())
pd.set_option('display.max_columns', None)
reticulate::repl_python()
#import geoplot as gplt
import geopandas as gpd
#import geoplot.crs as gcrs
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import mapclassify as mc
import numpy as np
from geopy.geocoders import Nominatim
from shapely.geometry import Point
import os
from pandasql import sqldf
import matplotlib.pyplot as plt
import matplotlib as mpl
import datetime
import numpy as np
pysqldf = lambda q: sqldf(q, globals())
pd.set_option('display.max_columns', None)
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()
#["EVSE-L01","EVSE-L02","EVSE-L03"]
grp_ch_stn
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()["EVSE-L01","EVSE-L02","EVSE-L03"]
grp_ch_stn
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
grp_ch_stn
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
grp_ch_stn.sum()
# load charging station data
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
# load vehicle registrations data
df_veh_reg = pd.read_parquet("../Data/Transport/Experian Registrations/sum_registrations.parquet")
df_veh_reg
# load charging station data
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
# load vehicle registrations data
df_veh_reg = pd.read_parquet("../Data/Transport/Experian Registrations/sum_registrations.parquet")
df_veh_reg
# load charging station data
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
# load vehicle registrations data
df_veh_reg = pd.read_parquet("../Data/Transport/Experian Registrations/sum_registrations.parquet")
df_veh_reg
# load charging station data
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
# load vehicle registrations data
df_veh_reg = pd.read_parquet("../Data/Transport/Experian Registrations/sum_registrations.parquet")
df_veh_reg
# load charging station data
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
# load vehicle registrations data
df_veh_reg = pd.read_parquet("../Data/Transport/Experian Registrations/sum_registrations.parquet")
df_veh_reg
#import geoplot as gplt
import geopandas as gpd
#import geoplot.crs as gcrs
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import mapclassify as mc
import numpy as np
from geopy.geocoders import Nominatim
from shapely.geometry import Point
import os
from pandasql import sqldf
import matplotlib.pyplot as plt
import matplotlib as mpl
import datetime
import numpy as np
pysqldf = lambda q: sqldf(q, globals())
pd.set_option('display.max_columns', None)
# load charging station data
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
# load vehicle registrations data
df_veh_reg = pd.read_parquet("../Data/Transport/Experian Registrations/sum_registrations.parquet")
df_veh_reg
# load charging station data
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
grp_ch_stn = df_ch_stn.groupby("GEOID").sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]]
# load vehicle registrations data
df_veh_reg = pd.read_parquet("../Data/Transport/Experian Registrations/sum_registrations.parquet")
df_veh_reg
reticulate::repl_python()
#import geoplot as gplt
import geopandas as gpd
#import geoplot.crs as gcrs
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import mapclassify as mc
import numpy as np
from geopy.geocoders import Nominatim
from shapely.geometry import Point
import os
from pandasql import sqldf
import matplotlib.pyplot as plt
import matplotlib as mpl
import datetime
import numpy as np
pysqldf = lambda q: sqldf(q, globals())
pd.set_option('display.max_columns', None)
# load charging station data
df_ch_stn = pd.read_csv("../Data/Transport/alt_fuel_stations_w_county.csv")
# filter out the private stations
print("df_ch_stn all",df_ch_stn.shape[0])
df_ch_stn = df_ch_stn[df_ch_stn["Access Code"]=="public"]
print("df_ch_stn no private",df_ch_stn.shape[0])
df_ch_stn = df_ch_stn[pd.notnull(df_ch_stn["Open Date"])]
print("df_ch_stn (after removing nan open year",df_ch_stn.shape[0])
df_ch_stn = df_ch_stn.assign(year=pd.to_datetime(df_ch_stn.loc[:,'Open Date']).dt.year.astype(int))
grp_ch_stn = df_ch_stn.groupby(["GEOID","year"]).sum()[["EVSE-L01","EVSE-L02","EVSE-L03"]].reset_index()
grp_ch_stn["cEVSE-L01"]=grp_ch_stn[["GEOID","EVSE-L01"]].groupby("GEOID").cumsum()
grp_ch_stn["cEVSE-L02"]=grp_ch_stn[["GEOID","EVSE-L02"]].groupby("GEOID").cumsum()
grp_ch_stn["cEVSE-L03"]=grp_ch_stn[["GEOID","EVSE-L03"]].groupby("GEOID").cumsum()
grp_ch_stn["cEVSE"]=grp_ch_stn["cEVSE-L01"]+grp_ch_stn["cEVSE-L02"]+grp_ch_stn["cEVSE-L03"]
# load vehicle registrations data
df_veh_reg = pd.read_parquet("../Data/Transport/Experian Registrations/sum_registrations.parquet")
# fill nan with zero and aggregate electricity columns
df_veh_reg.fillna(0, inplace=True)
df_veh_reg = df_veh_reg.assign(bev=df_veh_reg["24kw Electric~Electric"]+df_veh_reg["60kw Electric~Electric"]+df_veh_reg["85kw Electric~Electric"]+df_veh_reg["90kw Electric~Electric"]+df_veh_reg["Electric"]+df_veh_reg["Electric Fuel System"])
df_veh_reg = df_veh_reg.assign(pev=(df_veh_reg["bev"]+df_veh_reg["Plug-In Hybrid"]))
# percent bev is bev/total vehicles
df_veh_reg = df_veh_reg.assign(per_bev=df_veh_reg["bev"] / df_veh_reg["All"])
# percent pev is (bev+phev)/total vehicles
df_veh_reg = df_veh_reg.assign(per_pev=df_veh_reg["pev"] / df_veh_reg["All"])
# combine registration and charging data by year and county code
df = df_veh_reg.merge(grp_ch_stn.loc[:,["GEOID","year","cEVSE-L01","cEVSE-L02","cEVSE-L03","cEVSE"]],how="left",left_on=["GEOID","year"],right_on=["GEOID","year"])
# add additional columns for lagged charging station counts
df["lag_year"] = df.year-1
df = df.merge(grp_ch_stn.loc[:,["GEOID","year","cEVSE-L01","cEVSE-L02","cEVSE-L03","cEVSE"]],how="left",left_on=["GEOID","lag_year"],right_on=["GEOID","year"],suffixes=("","_lag"))
df["GEOID"] = df["GEOID"].astype(int)
# read in demographic data by county and add to main dataframe
df_pop11 = pd.read_csv("../Data/Census/county_pop_race_age_2011_2015.csv")
df_pop15 = pd.read_csv("../Data/Census/county_pop_race_age_2015_2019.csv")
# read in egrid data and add to main dataframe
# join demographics to main dataframe for 2011 to 2015
df11 = df.loc[df.year<2015,:].merge(df_pop11, how="left", left_on="GEOID", right_on="GEOID")
# update data for years 2015 forward to use the 2015-2019 data
df15 = df.loc[df.year>=2015,:].merge(df_pop15, how="left", left_on="GEOID", right_on="GEOID")
df = pd.concat((df11,df15),axis=0)
# some data are assigned county codes that don't appear in the population dataset. They should be removed for analysis.
df.dropna(axis=0,subset="ALUBE001", inplace=True)
# calculate per capita statistics (per 100,000 inhabitants)
df["bev_cap"] = (df["bev"]/df["ALUBE001"])*100000
df["pev_cap"] = (df["pev"]/df["ALUBE001"])*100000
df["cEVSE-L01_cap"] = (df["cEVSE-L01"]/df["ALUBE001"])*100000
df["cEVSE_L02_cap"] = (df["cEVSE-L02"]/df["ALUBE001"])*100000
df["cEVSE_L03_cap"] = (df["cEVSE-L03"]/df["ALUBE001"])*100000
df["cEVSE_cap"] = (df["cEVSE"]/df["ALUBE001"])*100000
df["cEVSE_cap_lag"] = (df["cEVSE_lag"]/df["ALUBE001"])*100000
df.fillna(0,inplace=True) # careful using a blanket fillna statement on a dataframe
df.sort_values(by=["GEOID","year"],inplace=True)
temp = df.GEOID.value_counts()==5 # data available for all years. Some remote areas and reservations do not have data available for all years
df = df[df.GEOID.isin(temp[temp].index.get_level_values(0).values)]
#| layout-ncol: 1
#| fig-cap:
#|   - "US BEV Registrations and Charging Stations"
plt.style.use('seaborn-whitegrid')
us_tot = df.groupby("year").sum().reset_index()
us_tot["bev_cap"] = (us_tot["bev"]/us_tot["ALUBE001"])*100000
us_tot["cEVSE_cap"] = ((us_tot["cEVSE-L01"]+us_tot["cEVSE-L02"]+us_tot["cEVSE-L03"])/us_tot["ALUBE001"])*100000
fig, ax = plt.subplots()
x = us_tot.year
y1 = us_tot.bev_cap
y2 = us_tot.cEVSE_cap
ax2 = ax.twinx()
ln1 = ax.plot(x, y1, '-b', label='BEVs')
ln2 = ax2.plot(x,y2, '--r', label="Charging stations")
ax.set_xlabel('Year')
ax.set_ylabel('BEVs (per 100,000 persons)')
ax2.set_ylabel('Charging stations (per 100,000 persons)')
ax2.grid(False)
lns = ln1+ln2
labs = [l.get_label() for l in lns]
ax.legend(lns, labs, loc='upper left', frameon=True);
plt.show()
US_sf = gpd.read_file("../Data/GIS/cb_2018_us_county_5m/cb_2018_us_county_5m.shp")
station_data = pd.read_csv("../Data/Transport/alt_fuel_stations.csv")
#Removing the outlying islands and other territories.
US_sf["STATEFP"] =pd.to_numeric(US_sf["STATEFP"])
US_sf = US_sf[US_sf['STATEFP'] < 57]
US_sf = US_sf[US_sf['COUNTYNS'] != "01419965"]
US_sf = US_sf.to_crs(4326)
geometry = [Point(xy) for xy in zip(station_data.Longitude, station_data.Latitude)]
crs = {'init' :'epsg:4326'}
station_points = gpd.GeoDataFrame(station_data, crs=crs, geometry=geometry)
station_points = gpd.sjoin(station_points, US_sf, how='left', predicate='within')
merged_df = pd.DataFrame(station_points)
state_pop = pd.read_csv("../Data/Census/PopByState/nst-est2019-01.csv")
state_pop['State'] = state_pop['Geographic Area'].map(us_state_to_abbrev)
sns.set_theme()
sns.set(rc = {'figure.figsize':(15,8)})
timeseriesx = []
timeseriesy = []
merged_df['Open Date'] = pd.to_datetime(merged_df['Open Date'])
yearpop = 2019
merged_year = merged_df.loc[merged_df['Open Date'] < datetime.datetime(yearpop,12,31)]
num_stations_by_state = merged_year['State'].value_counts()
num_stations_by_state = pd.DataFrame(num_stations_by_state)
num_stations_by_state = num_stations_by_state.reset_index()
num_stations_by_state.columns = ['State','Charging Stations']
drop = ["PR", "ON"]
num_stations_by_state = num_stations_by_state[num_stations_by_state.State.isin(drop) == False]
ev_market_share = pd.read_csv("../Data/Transport/BEV-PHEV-HEV-FCEV-ICE-Sales-By State-2011-2020-EVAdoption-7.13.21.csv")
stations_vs_marketshare = pd.merge(state_pop, num_stations_by_state, left_on= "State", right_on="State", how = "right")
stations_vs_marketshare = pd.merge(stations_vs_marketshare, ev_market_share, left_on= "Geographic Area", right_on="State", how = "left")
stations_vs_marketshare['Stations Per Capita'] = (stations_vs_marketshare['Charging Stations']/stations_vs_marketshare[str(yearpop)])*1000
stations_vs_marketshare['EV (BEV & PHEV) Share'] = stations_vs_marketshare['EV (BEV & PHEV) Share']*100
stations_vs_marketshare[['Geographic Area', 'Stations Per Capita','EV (BEV & PHEV) Share']].head()
share_v_stations_plot = sns.scatterplot(
data = stations_vs_marketshare,
x="Stations Per Capita", y="EV (BEV & PHEV) Share",
)
share_v_stations_plot.set_xlabel("Charging Stations per Capita")
share_v_stations_plot.set_ylabel("BEV+PHEV Market Share (%)")
share_v_stations_plot.set_title(year)
share_v_stations_plot.set(xlim=(0, 0.4))
share_v_stations_plot.set(ylim=(0, 10))
# Just for fun
state_labels = ["California", "Vermont", "Texas"]
i = 0
# for state in stations_vs_marketshare['Geographic Area']:
for state in state_labels:
x = stations_vs_marketshare.loc[stations_vs_marketshare['Geographic Area'] == state, 'Stations Per Capita'].iloc[0]
y = stations_vs_marketshare.loc[stations_vs_marketshare['Geographic Area'] == state, 'EV (BEV & PHEV) Share'].iloc[0]
share_v_stations_plot.text(x + 0.005, y - 0.001 , state)
timeseriesx.append([])
timeseriesy.append([])
timeseriesx[i].append(x)
timeseriesy[i].append(y)
i = i + 1
plt.show()
#  https://gist.github.com/rogerallen/1583593
us_state_to_abbrev = {
"Alabama": "AL",
"Alaska": "AK",
"Arizona": "AZ",
"Arkansas": "AR",
"California": "CA",
"Colorado": "CO",
"Connecticut": "CT",
"Delaware": "DE",
"Florida": "FL",
"Georgia": "GA",
"Hawaii": "HI",
"Idaho": "ID",
"Illinois": "IL",
"Indiana": "IN",
"Iowa": "IA",
"Kansas": "KS",
"Kentucky": "KY",
"Louisiana": "LA",
"Maine": "ME",
"Maryland": "MD",
"Massachusetts": "MA",
"Michigan": "MI",
"Minnesota": "MN",
"Mississippi": "MS",
"Missouri": "MO",
"Montana": "MT",
"Nebraska": "NE",
"Nevada": "NV",
"New Hampshire": "NH",
"New Jersey": "NJ",
"New Mexico": "NM",
"New York": "NY",
"North Carolina": "NC",
"North Dakota": "ND",
"Ohio": "OH",
"Oklahoma": "OK",
"Oregon": "OR",
"Pennsylvania": "PA",
"Rhode Island": "RI",
"South Carolina": "SC",
"South Dakota": "SD",
"Tennessee": "TN",
"Texas": "TX",
"Utah": "UT",
"Vermont": "VT",
"Virginia": "VA",
"Washington": "WA",
"West Virginia": "WV",
"Wisconsin": "WI",
"Wyoming": "WY",
"District of Columbia": "DC",
"American Samoa": "AS",
"Guam": "GU",
"Northern Mariana Islands": "MP",
"Puerto Rico": "PR",
"United States Minor Outlying Islands": "UM",
"U.S. Virgin Islands": "VI",
}
#  https://gist.github.com/rogerallen/1583593
us_state_to_abbrev = {
"Alabama": "AL",
"Alaska": "AK",
"Arizona": "AZ",
"Arkansas": "AR",
"California": "CA",
"Colorado": "CO",
"Connecticut": "CT",
"Delaware": "DE",
"Florida": "FL",
"Georgia": "GA",
"Hawaii": "HI",
"Idaho": "ID",
"Illinois": "IL",
"Indiana": "IN",
"Iowa": "IA",
"Kansas": "KS",
"Kentucky": "KY",
"Louisiana": "LA",
"Maine": "ME",
"Maryland": "MD",
"Massachusetts": "MA",
"Michigan": "MI",
"Minnesota": "MN",
"Mississippi": "MS",
"Missouri": "MO",
"Montana": "MT",
"Nebraska": "NE",
"Nevada": "NV",
"New Hampshire": "NH",
"New Jersey": "NJ",
"New Mexico": "NM",
"New York": "NY",
"North Carolina": "NC",
"North Dakota": "ND",
"Ohio": "OH",
"Oklahoma": "OK",
"Oregon": "OR",
"Pennsylvania": "PA",
"Rhode Island": "RI",
"South Carolina": "SC",
"South Dakota": "SD",
"Tennessee": "TN",
"Texas": "TX",
"Utah": "UT",
"Vermont": "VT",
"Virginia": "VA",
"Washington": "WA",
"West Virginia": "WV",
"Wisconsin": "WI",
"Wyoming": "WY",
"District of Columbia": "DC",
"American Samoa": "AS",
"Guam": "GU",
"Northern Mariana Islands": "MP",
"Puerto Rico": "PR",
"United States Minor Outlying Islands": "UM",
"U.S. Virgin Islands": "VI",
}
library(tidyverse)
library(arrow)
library(readr)
library(AICcmodavg) # Add the ANOVA package
#NEED TO SWAP BETWEEN!!!
#Jason's
exp_data = read_parquet("../EV-Chicken and Egg Project/Data/Transport/Experian Registrations/US_Fleet_County_2021Q4.parquet",col_select=c("County Code","County Code","Vehicle Category",""))
setwd("C:/Users/jhawkins17/University of Nebraska-Lincoln/UNL-Hawkins Research Group - Documents/Rural EV Adoption Project")
#NEED TO SWAP BETWEEN!!!
#Jason's
exp_data = read_parquet("../EV-Chicken and Egg Project/Data/Transport/Experian Registrations/US_Fleet_County_2021Q4.parquet",col_select=c("County Code","County Code","Vehicle Category",""))
#NEED TO SWAP BETWEEN!!!
#Jason's
exp_data = read_parquet("../EV-Chicken and Egg Project/Data/Transport/Experian Registrations/US_Fleet_County_2021Q4.parquet",col_select=c("State Code","County Code","Vehicle Category",""))
#NEED TO SWAP BETWEEN!!!
#Jason's
exp_data = read_parquet("../EV-Chicken and Egg Project/Data/Transport/Experian Registrations/US_Fleet_County_2021Q4.parquet",col_select=c("State Code","County Code","Vehicle Category"))
# Combine state/county codes to get a unique id
exp_data$UIDCTY = ifelse(exp_data$`County Code`<10,paste(exp_data$`State Code`,exp_data$`County Code`,sep="00"),ifelse(exp_data$`County Code`<100,paste(exp_data$`State Code`,exp_data$`County Code`,sep="0"),paste(exp_data$`State Code`,exp_data$`County Code`,sep="")))
exp_data$GEOID <- as.numeric(as.character(exp_data$UIDCTY))
#NEED TO SWAP BETWEEN!!!
#Jason's
NCHSURCodes2013 <- read_csv("NCHSURCodes2013.csv")
comb_exp_cty = exp_data%>%left_join(NCHSURCodes2013, by=c("GEOID"="FIPS code"))
# Filter out incomplete vehicles
exp_data <- comb_exp_cty[comb_exp_cty$'Vehicle Category'!='Incomplete Vehicle' , ]
ct_reg_cty_type_cat = exp_data%>%group_by(`GEOID`,`Vehicle Category`)%>%summarise(n=n())
# With filtered results, % vehicles that are light trucks by county
ct_reg_cty_type_cat2 <- aggregate(n ~ GEOID, data=ct_reg_cty_type_cat, sum)
ct_reg_cty_type_cat2$total_vehicles <-ct_reg_cty_type_cat2$n
ct_reg_cty_type_cat_sum <- ct_reg_cty_type_cat%>%left_join(ct_reg_cty_type_cat2, by=c("GEOID"="GEOID"))
ct_reg_cty_type_cat_sum$percent_total <-((ct_reg_cty_type_cat_sum$n.x/ct_reg_cty_type_cat_sum$n_sum)*100)
ct_reg_cty_type_cat_sum_truck <- ct_reg_cty_type_cat_sum[ct_reg_cty_type_cat_sum$'Vehicle Category'=='Light Truck' , ]
# How does that percent vary across urban/rural groups - ANOVA analysis within group vs. between groups
ct_reg_cty_type_cat_sum_truck$percentages<-((ct_reg_cty_type_cat_sum_truck$n.x/ct_reg_cty_type_cat_sum_truck$total_vehicles)*100)
ct_reg_cty_type_cat_sum$n.x
ct_reg_cty_type_cat_sum_truck$total_vehicles
ct_reg_cty_type_cat_sum$n.x/ct_reg_cty_type_cat_sum$n_sum
ct_reg_cty_type_cat_sum <- ct_reg_cty_type_cat%>%left_join(ct_reg_cty_type_cat2, by=c("GEOID"="GEOID"))
ct_reg_cty_type_cat_sum$percent_total <-((ct_reg_cty_type_cat_sum$n.x/ct_reg_cty_type_cat_sum$n_sum)*100)
ct_reg_cty_type_cat_sum[ct_reg_cty_type_cat_sum$'Vehicle Category'=='Light Truck' , ]
ct_reg_cty_type_cat_sum$percent_total <-((ct_reg_cty_type_cat_sum$n.x/ct_reg_cty_type_cat_sum$n_sum)*100)
ct_reg_cty_type_cat_sum$percent_total
((ct_reg_cty_type_cat_sum$n.x/ct_reg_cty_type_cat_sum$n_sum)*100)
((ct_reg_cty_type_cat_sum$n.x
))
ct_reg_cty_type_cat_sum <- ct_reg_cty_type_cat%>%left_join(ct_reg_cty_type_cat2, by=c("GEOID"="GEOID"))
ct_reg_cty_type_cat_sum
ct_reg_cty_type_cat
ct_reg_cty_type_cat2
ct_reg_cty_type_cat_sum$percent_total <-((ct_reg_cty_type_cat_sum$n.x/ct_reg_cty_type_cat_sum$total_vehicles)*100)
ct_reg_cty_type_cat_sum_truck <- ct_reg_cty_type_cat_sum[ct_reg_cty_type_cat_sum$'Vehicle Category'=='Light Truck' , ]
# How does that percent vary across urban/rural groups - ANOVA analysis within group vs. between groups
ct_reg_cty_type_cat_sum_truck$percentages<-((ct_reg_cty_type_cat_sum_truck$n.x/ct_reg_cty_type_cat_sum_truck$total_vehicles)*100)
trucks_percent_with_codes = ct_reg_cty_type_cat_sum_truck%>%left_join(NCHSURCodes2013, by=c("GEOID"="FIPS code"))
trucks_percent_with_codes$NHTS_version <- recode(trucks_percent_with_codes$`2013 code`,'1'="1",'2'="1",'3'="2",'4'="3",'5'="4",'6'="4")
view(trucks_percent_with_codes)
one.way <- aov(percentages ~ `2013 code`, data = trucks_percent_with_codes)
summary(one.way)
trucks_percent_with_codes
